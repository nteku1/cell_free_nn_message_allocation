# -*- coding: utf-8 -*-
"""Solov_Revised_2_17_ AVG_of ZEROS_VER3_Copy of SINGLE_COMBINE_TESTING_FIXED_Copy of Copy of Copy of EXP_rev_ Copy of USE_THIS_ACTUAL_SHAD_10_AP_3_UE_GENERALIZE_MULT_UE_Copy_7_16_TRYINGSTUFF_EXP_Copy_MULTI_Copy_ MORE_EXPERIMENTS_TESTING_CHECKING_EXP_Copy of EXP_TRY_DIFF_STRUCTURE_Copy of VER2_6_24_postmeeting_Copy_SIGMOID_WORKS_BUTCONSTANT_OUTPUT_ LATEST_COPY_FIXED_ddpg_sim_JUST_RATE_NO_ALPHA_updated.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10iISRb6BOu1cmYydvnZ9lWEimlx0j5VC
"""


import tensorflow as tf
from tensorflow.keras import layers
import numpy as np
import matplotlib.pyplot as plt


tf.keras.utils.set_random_seed(15)



file1 = open('EFBACTUAL_RREDO_100meters_PRETTY_PLS_VER551_MULTIPLE_PATHS_LARGE_VER1_10AP_6_UE_50000SHAD.txt', 'r')
lines = file1.readlines()

num_APs = 10 #20 #20 #20 #25 #20#10
num_user = 6 #3#6 #40 #20
pos = 0
raw_iq = []
complex_vec = []
complex_vec_total = []
count = 0
count2 = 0

for i in range(num_user):
  temp = lines[pos+i]
  temp = temp.strip()
  temp = temp.split(' ')
  raw_iq.append(temp)
  print(raw_iq[i])

for i in range(num_user):
  for jslack in raw_iq[i]:
  #i = float(i)
    if count % 2 == 0:
      tens = float(raw_iq[i][count])
    if  count % 2 == 1:
      complex_vec.append(complex(tens,float(raw_iq[i][count])))
      count2 = count2+ 1
    count = count + 1
  complex_vec_total.append(complex_vec)
  complex_vec = []
  count = 0
  count2 = 0

print(complex_vec_total[0])
print(complex_vec_total[1])

def converttt(lines,id):  
  raw_iq = []
  complex_vec = []
  complex_vec_total = []
  count = 0
  count2 = 0

  for i in range(num_user):
    temp = lines[id+i]
    temp = temp.strip()
    temp = temp.split(' ')
    raw_iq.append(temp)
    #print(raw_iq[i])

  for i in range(num_user):
    for jslack in raw_iq[i]:
    #i = float(i)
      if count % 2 == 0:
        tens = float(raw_iq[i][count])
      if  count % 2 == 1:
        complex_vec.append(complex(tens,float(raw_iq[i][count])))
        count2 = count2+ 1
      count = count + 1
    complex_vec_total.append(complex_vec)
    complex_vec = []
    count = 0
    count2 = 0

  return complex_vec_total
  #print(complex_vec_total[0])
  #print(complex_vec_total[1])

freq = 1*10**6
B = 20*10**6
C = 20
S_u = 10**3
beta1 = 1
beta2 = 1 #100 for chan 1, 10 for chan 2, 1 for chan 3
p = 100 #100 #(mW)
ada_1 = 1
num_actions = num_APs
num_states = 2*num_APs # ust passing rate
#num_states = num_APs +num_APs#state requires alphas of each AP and channel gains between each AP and the user
'''
problem = "Pendulum-v0"
env = gym.make(problem)

num_states = env.observation_space.shape[0]
print("Size of State Space ->  {}".format(num_states))
num_actions = env.action_space.shape[0]
print("Size of Action Space ->  {}".format(num_actions))
'''

lower_bound = 0
upper_bound = 1
#upper_bound = env.action_space.high[0]
#lower_bound = env.action_space.low[0]

print("Max Value of Action ->  {}".format(upper_bound))
print("Min Value of Action ->  {}".format(lower_bound))




            


        

        





def update(
        state_batch, gain_critic
):
    # Training and updating Actor & Critic networks.
    # See Pseudo Code.
    # TRY TO DO DIFFERENCE OF SHUFFLED ALPHAS???

    with tf.GradientTape() as tape:
        final_lats = []
        cccc = 0
        id = 0

        comp_lats = []
        trans_lats = []
        critic_value = tf.zeros([num_APs])
        anti_indices = []
        anti_update = []
        copy_crit_indices = []

        for jslack in gain_critic:
            UE_state = np.concatenate((np.array(state_batch[0]),np.array(jslack)))
            temp_fw = critic_model((tf.expand_dims(UE_state, 0)))[0]
            temp_indices = np.argsort(temp_fw)[6:]
            temp_count = 0

            for isl in range(len(temp_fw)):
                if temp_count not in temp_indices:
                    temp_fw = tf.tensor_scatter_nd_update(temp_fw, [[temp_count]], [0])
                elif temp_fw[temp_count] < 0:
                    temp_fw = tf.tensor_scatter_nd_update(temp_fw, [[temp_count]], [temp_fw[temp_count] * -1])
                    # temp_fw = tf.tensor_scatter_nd_update(temp_fw, [[temp_count]], [0])
                temp_count += 1

            crit_indices = tf.experimental.numpy.where(temp_fw == 0)
            copy_crit_indices.append(crit_indices[0])
            crit_list = []
            cn = 0

            for ist in range(len(crit_indices[0])):
                crit_list.append([])
                for istt in range(1):
                    crit_list[ist].append(crit_indices[0][istt + cn])
                cn += 1

            anti_indices.append(crit_list)
            update_list = []

            for upp in range(len(crit_indices[0])):
                # update_list.append(crit_indices[0][upp*-1])
                update_list.append(0)
            anti_update.append(update_list)

            '''
            new_critic_value = tf.tensor_scatter_nd_update(temp_fw, crit_list, update_list)
            new_critic_value = new_critic_value/tf.math.reduce_sum(new_critic_value)
            critic_value = tf.concat([critic_value, new_critic_value], axis=0)
            '''
            if len(crit_list) != 0:
                new_critic_value = tf.tensor_scatter_nd_update(temp_fw, crit_list, update_list)
                new_critic_value = new_critic_value / tf.math.reduce_sum(new_critic_value)
                critic_value = tf.concat([critic_value, new_critic_value], axis=0)
            else:
                # critic_value = tf.concat([critic_value, temp_fw], axis=0)
                # line below is in the case of softmax not being the ouput layer
                critic_value = tf.concat([critic_value, temp_fw / tf.math.reduce_sum(temp_fw)], axis=0)

        critic_value = critic_value[num_APs:]
        sum_temptf = tf.zeros([num_APs], dtype='float64')
        sum_dentf = tf.zeros([num_APs], dtype='float64')

        for gan in range(num_user):
            alph = critic_value[gan * num_APs:num_APs + gan * num_APs]
            ########################product = alphasss*S_u
            omsquared = (1 - alph) ** 2
            squ = alph ** 2

            gain_vec = gain_critic[gan]#gain_critic[id][gan]
            if len(anti_indices[gan]) != 0 and len(anti_update[gan]) != 0:
                gain_vec = tf.tensor_scatter_nd_update(gain_vec, anti_indices[gan], anti_update[gan])
            gain_vec = tf.cast(gain_vec, dtype='float32')
            chansd = ((gain_vec) ** 2)  # (np.absolute(gain_critic[id][gan]) ** 2)

            # num = ((B*np.log2(1+((p*ada_1)*(squareddd*chan_squared)))))
            ###########################den = 1+ ((p*ada_1)*(oneminussquared*chan_squared))
            dpp = ((p * ada_1) * (omsquared * chansd))

            tep = (((p * ada_1) * (squ * chansd)))
            ############################rate = ((B*np.log2((1+(((p*ada_1)*(squareddd*chan_squared))/den)))))
            dpp = tf.cast(dpp, dtype='float64')
            tep = tf.cast(tep, dtype='float64')

            sum_dentf = sum_dentf + dpp
            sum_temptf = sum_temptf + tep



            # should do this if somehow channel becomes zero (i.e. shadow)
        frustrating_constant = tf.constant(1, dtype='float64')
        oldies = ((sum_temptf) / (1 + sum_dentf))
        rat = ((B * np.log2((frustrating_constant + ((sum_temptf) / (1 + sum_dentf))))))
        id += 1

        for vin in range(num_user):
            if len(anti_indices[vin]) != 0 and len(anti_update[vin]) != 0:
                new_rat = tf.tensor_scatter_nd_update(rat, anti_indices[vin], anti_update[vin])
            else:
                new_rat = rat
            new_rat = tf.cast(new_rat, dtype='float32')
            new_rat = new_rat[new_rat != 0]

            comp_lats.append(tf.cast(beta1 * critic_value[vin * num_APs:num_APs + vin * num_APs] * S_u, tf.float32))
            trans_lats.append(tf.math.reduce_max(tf.cast((beta2 * (
            critic_value[vin * num_APs:num_APs + vin * num_APs][
                critic_value[vin * num_APs:num_APs + vin * num_APs] != 0] * S_u / new_rat)), tf.float32)))
            '''
            #Original latency
            first_term = tf.cast((beta1 * (critic_value[vin*num_APs:num_APs+vin*num_APs][critic_value[vin*num_APs:num_APs+vin*num_APs]!=0] * S_u * C) / freq), tf.float32)
            second_term = tf.cast((beta2 * (critic_value[vin*num_APs:num_APs+vin*num_APs][critic_value[vin*num_APs:num_APs+vin*num_APs]!=0]*S_u / new_rat)), tf.float32)
            lats.append(tf.math.reduce_max(first_term + second_term))
            '''
        # (tf.expand_dims(tf.convert_to_tensor(prev_state[jwiw], dtype=np.float32), 0))
        tf_actual_comp = tf.math.reduce_sum(comp_lats, axis=0)
        tf_actual_comp = tf.math.reduce_max((tf_actual_comp * C) / freq)
        tf_actual_trans = tf.math.reduce_mean(trans_lats)
        final_lats.append(tf_actual_comp + tf_actual_trans)
        cccc += 1

        critic_loss = tf.math.reduce_mean(final_lats)
    ##############3critic_loss = tf.math.reduce_sum(final_lats) #??
    # critic_loss = tf.math.reduce_max(final_lats)

    critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables)
    # critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables)
    critic_optimizer.apply_gradients(
        zip(critic_grad, critic_model.trainable_variables)
    )

    return critic_value,critic_loss,oldies


def get_critic():
    # State as input
    state_input = layers.Input(shape=(num_states))
    #state_out = layers.Dense(16, activation="tanh")(state_input)
    #state_out = layers.Dense(32, activation="tanh")(state_out)

    # Action as input
    ############################action_input = layers.Input(shape=(num_actions))
    #action_out = layers.Dense(32, activation="tanh")(action_input)

    # Both are passed through seperate layer before concatenating
    #concat = layers.Concatenate()([state_out, action_out])
    ################################concat = layers.Concatenate()([state_input, action_input])
    ############################ new
    out = layers.BatchNormalization()(state_input)   
    ##############################out = layers.BatchNormalization()(concat)    
    #out = layers.Dense(300, activation="softmax")(out)  #300
    #out = layers.Dropout(0.3)(out)
    #out = layers.BatchNormalization()(out)
    out = layers.Dense(128, activation="tanh",kernel_regularizer='l2')(out)  #128               256 sigmoid
    #out = layers.Dropout(0.3)(out)
    out = layers.BatchNormalization()(out)
    out = layers.Dense(64, activation="tanh",kernel_regularizer='l2')(out)  #64                           256 tanh
    #out = layers.Dropout(0.3)(out)
    out = layers.BatchNormalization()(out)
    outputs = layers.Dense(num_APs,activation="linear")(out)  #originally linear/softmax??, sigmoid matches unif
    # Outputs single value for give state-action
    model = tf.keras.Model(state_input, outputs)
    
    return model

def policy(state):
    sampled_actions = tf.squeeze(critic_model(state))

    legal_action = sampled_actions.numpy()  # /np.sum(sampled_actions.numpy())
    legal_indices = np.argsort(legal_action)[6:]  # 3
    id_count = 0
    for i in range(len(legal_action)):
        if id_count not in legal_indices:
            legal_action[id_count] = 0
        id_count += 1

    print('Removed indicies')
    print(legal_indices)
    for val in range(num_APs):
        if legal_action[val] < 0:
            legal_action[val] = legal_action[val] * -1  # 0

    # re-normalize
    legal_action = legal_action / np.sum(legal_action)

    return [np.squeeze(legal_action)]

def policy_testing(state):
    sampled_actions = tf.squeeze(critic_model(state))



    legal_action = sampled_actions.numpy()#/np.sum(sampled_actions.numpy())

    for val in range(num_APs):
      if legal_action[val] < 0:
        legal_action[val] = 0 #legal_action[val]*-1 #0

    #re-normalize
    legal_action = legal_action/np.sum(legal_action)


    return [np.squeeze(legal_action)]

std_dev = 0.2
#ou_noise = OUActionNoise(mean=np.zeros(1), std_deviation=float(std_dev) * np.ones(1))  
#ou_noise = OUActionNoise(mean=np.zeros(num_APs), std_deviation=float(std_dev) * np.ones(num_APs))  

critic_model = get_critic()


# Learning rate for actor-critic models
#These worked!!!
#####critic_lr = 0.02   
#####actor_lr = 0.001     

#tanh tanh linear

critic_lr = 0.0002 #0.002
#critic_lr = 0.000002  #0.02 was working 0.0002 was worse    0.000002
#7/12 - 7:49
#actor_lr = 0.0001 #0.0001  brings zeros       0.01 makes it close to uniform    7/11/morning12 - did 0.001 got better results

critic_optimizer = tf.keras.optimizers.Adam(critic_lr) #adam

total_episodes = 1 #1600 #300 #600 100!!!! #450 #90 20  200 works  wors   500 episodes





# To store reward history of each episode
ep_reward_list = []
solo1 = []
solo2 = []

# To store average reward history of last few episodes
const_reward_list = []
unif_reward_list = []
new_reward = 0
best_alphas = np.zeros(shape=(1,num_APs))
#best_alphas = np.zeros(shape=(1,10))
b1  = 0
indexxx = 0
stop_now = 0


# Takes about 4 min to train
for ep in range(total_episodes):

    #prev_state = env.reset() ep*1000
    prev_state = np.zeros([num_states,])
    episodic_reward = 0
    alphasss = []

    if stop_now == 1:
      break
    



    for i in range(num_user):
      #rand_vecs = np.zeros(shape=(1,num_APs))
      #rand_vecs = rand_vecs + ((1/num_APs)*np.ones(shape=(1,num_APs)))
      rand_vecs = np.random.random(size=(1,num_APs))
      rand_vecs = rand_vecs/np.sum(rand_vecs)
      alphasss.append(rand_vecs[0])
    


    indexxx = ep*200
    
    #indexxx = ep*1000
    #print('Step')
    #print(indexxx)
    #print(200+ep*200)
    '''
    comp, fla = converttt(lines,0)
    prev_state[0:10] = fla
    prev_state[10:21] = alphasss
    '''

    #while indexxx < len(lines)-1:
    #while indexxx < 200 + ep*200:
    while indexxx < 200 + 100*200:             
    #while indexxx < 15:
        # Uncomment this to see the Actor in action
        # But not in a python notebook.
        # env.render()
        #print(prev_state)
        #prev_state = np.asarray(prev_state).astype(np.float32)
        ############print(indexxx)   
        tf_prev_state = [[]]*num_user
        '''
        if indexxx > 0:
          print('Step')
          print(indexxx)
          for jwiw in range(num_user):
            tf_prev_state[jwiw] = (tf.expand_dims(tf.convert_to_tensor(prev_state[jwiw],dtype=np.float32), 0))

        else:
          for jwiw in range(num_user):
            #tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state[jwiw],dtype=np.float32), 0)
            tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state,dtype=np.float32), 0)
        '''

        #if indexxx == ep*1000: #1000: #0: 200
        if indexxx == 0:
          actions = []
          for ikea in range(num_user):
            actions.append(np.asarray(alphasss[ikea]))


        comp_latencies_co = []
        trans_latencies_co = []
        comp_latencies_u_co = []
        trans_latencies_u_co = []
        comp_latencies_b_co = np.zeros(shape=(1,num_APs))
        trans_latencies_b_co = []
        latencies_co = []
        copy_of_latencies_co = []
        copy_of_products_co = []
        copy_of_SINRS_co = []
        #copy_of_GAINS_co = np.absolute(complex_vec_total)
        latencies_u_co = []
        latencies_b_co = []
        sum_temp = np.zeros(shape=(1,num_APs))
        sum_den = np.zeros(shape=(1,num_APs))
        sum_temp_u = np.zeros(shape=(1,num_APs))
        sum_den_u = np.zeros(shape=(1,num_APs))
        sum_temp_b = []
        sum_den_b = []

        for swag in range(num_user):
            action = actions[swag]

            alphasss = action
            ########################product = alphasss*S_u
            oneminussquared = (1 - alphasss) ** 2
            squareddd = alphasss ** 2
            chan_squared = (np.absolute(complex_vec_total[swag]) ** 2)

            # num = ((B*np.log2(1+((p*ada_1)*(squareddd*chan_squared)))))
            ###########################den = 1+ ((p*ada_1)*(oneminussquared*chan_squared))
            den = ((p * ada_1) * (oneminussquared * chan_squared))

            temp = (((p * ada_1) * (squareddd * chan_squared)))
            ############################rate = ((B*np.log2((1+(((p*ada_1)*(squareddd*chan_squared))/den)))))


            sum_den[0] = sum_den[0] + den
            sum_temp[0] = sum_temp[0] + temp



            # should do this if somehow channel becomes zero (i.e. shadow)



        #un_dB_sinr = ((sum_temp) / (1 + sum_den))
        print('step')
        print(indexxx)
        if indexxx == 0:
            un_dB_sinr = ((sum_temp) / (1 + sum_den))
        else:
            un_dB_sinr = []
            un_dB_sinr.append(type_cast_sinr)

        indexxx = indexxx + num_user  # 2#1
        if indexxx < len(lines):
            complex_vec_total = (converttt(lines, indexxx))
            copy_of_GAINS_co = np.absolute(complex_vec_total)


        resulting_alphas,nn_latency,old_sinr = update(un_dB_sinr, copy_of_GAINS_co)
        actions = []
        type_cast_sinr = []
        for gan_step in range(num_user):
          actions.append(resulting_alphas[gan_step * num_APs:num_APs + gan_step * num_APs].numpy())

        for AP_id in range (num_APs):
            type_cast_sinr.append(old_sinr[AP_id].numpy())
        '''
        final_rewards = []
        for fight in range(num_user):
          final_rewards.append(np.max(latencies_co[fight]))
        '''

        #xx1 = np.max(latencies_co[0])
        #xx2 = np.max(latencies_co[1])
        #reward =np.mean([xx1, xx2]) 
        '''
        if indexxx == ep*200:
          reward =np.mean([xx1, xx2]) 
          old_reward = reward
        else:
          reward =np.mean([xx1, xx2]) 
          reward = reward - old_reward
          old_reward = reward
        '''

        ##### UNIFORM
        unif_actions = []
        for delicious in range(num_user):
            # unif_alphasss = 1/num_APs*np.ones([1,num_APs])
            # unif_alphasss = 1/10*np.ones([1,10])
            unif_alphasss = 1 / 4 * np.ones([1, 10])[0]
            xcel = np.random.choice(10, 4, replace=False)
            for slap in range(len(unif_alphasss)):
                if slap not in xcel:
                    unif_alphasss[slap] = 0
            unif_actions.append(unif_alphasss)

            product_u = unif_alphasss * S_u
            oneminussquared_u = (1 - unif_alphasss) ** 2
            squareddd_u = unif_alphasss ** 2
            chan_squared_u = (np.absolute(complex_vec_total[delicious]) ** 2)

            # num = ((B*np.log2(1+((p*ada_1)*(squareddd*chan_squared)))))
            ########################den_u = 1+ ((p*ada_1)*(oneminussquared_u*chan_squared_u))
            den_u = ((p * ada_1) * (oneminussquared_u * chan_squared_u))
            temp_u = (((p * ada_1) * (squareddd_u * chan_squared_u)))

            sum_den_u[0] = sum_den_u[0] + den_u
            sum_temp_u[0] = sum_temp_u[0] + temp_u
            comp_latencies_u_co.append(beta1 * (unif_alphasss * S_u))
            #####trans_latencies_u_co.append(np.max(beta2*(product_u/rate_u)))

            #########rate_u = ((B*np.log2((1+(((p*ada_1)*(squareddd_u*chan_squared_u))/den_u)))))

        rate_u = ((B * np.log2((1 + ((sum_temp_u) / (1 + sum_den_u))))))
        actual_comp_lat_u = np.sum(comp_latencies_u_co, axis=0)  # np.max(comp_latencies_co)
        actual_comp_lat_u = np.max((actual_comp_lat_u * C) / freq)

        for sewn in range(num_user):
            new_rate_u = rate_u[0].copy()
            zero_u_indic = np.where(unif_actions[sewn] == 0)[0]

            for i in zero_u_indic:  # setting rates where alpha = 0 to zero
                new_rate_u[i] = 0

            new_alphasss_u = unif_actions[sewn][unif_actions[sewn] != 0]

            observing_rate_indices = np.where(new_rate_u == 0)[0]
            observing_alphasss_indices = np.where(unif_actions[sewn] == 0)[0]
            observing_alphasss_indices_extra = np.where(unif_actions[sewn] != 0)[0]
            tezerk = len(observing_rate_indices)
            tezerk2 = len(observing_alphasss_indices)

            if tezerk != tezerk2:
                print('Size Damn it')
                quit()

            for excak in range(tezerk):
                if observing_rate_indices[excak] != observing_alphasss_indices[excak]:
                    print('Damn it')
                    quit()

            new_rate_u = new_rate_u[new_rate_u != 0]
            product_u = new_alphasss_u * S_u
            product_u = product_u[product_u != 0]
            trans_latencies_u_co.append(np.max(beta2 * (product_u / new_rate_u)))

        actual_trans_lat_u = np.mean(trans_latencies_u_co)
        # total_latency_u = (beta1*(unif_alphasss*S_u*C)/freq) + (beta2*(product_u/rate_u))
        # total_latency_u =  (beta2*(product_u/rate_u))
        # because alphas are always uniform for both users, can just multiply reward by 2.

        reward_u = actual_trans_lat_u + actual_comp_lat_u  # np.max(total_latency_u[0])   #2*


        '''
        if indexxx == ep*200:
          reward_u = np.max(total_latency_u[0])  
          old_reward_u = reward_u
        else:
          reward_u = np.max(total_latency_u[0])   
          reward_u = reward_u - old_reward_u
          old_reward_u = reward_u
        '''
          



        '''
        latencies_u_co.append(total_latency_u[0])
        xx1_u = np.max(latencies_u_co[0])
        xx2_u = np.max(latencies_u_co[1])
        reward_u =np.sum([xx1_u, xx2_u]) 
       '''
        
 
        
        unif_reward_list.append(reward_u)

        best_channel_gains = []
        #### BEST Method
        for great in range(num_user):
          best_id = np.argmax(np.abs(complex_vec_total)[great])
          best_channel_gains.append(best_id)
          best_alphasss = 1

          product_b = best_alphasss*S_u
          oneminussquared_b = (1-best_alphasss)**2
          squareddd_b = best_alphasss**2

          chan_squared_b = (np.absolute(complex_vec_total[great][best_id])**2)

          #num = ((B*np.log2(1+((p*ada_1)*(squareddd*chan_squared)))))
          #####################den_b = 1+ ((p*ada_1)*(oneminussquared_b*chan_squared_b))
          den_b = ((p*ada_1)*(oneminussquared_b*chan_squared_b))
          temp_b = (((p*ada_1)*(squareddd_b*chan_squared_b)))
          sum_den_b.append(den_b)
          sum_temp_b.append(temp_b)
          #####################rate_b = ((B*np.log2((1+(((p*ada_1)*(squareddd_b*chan_squared_b))/den_b)))))
        
        duplicates = []
        best_sums = []
        for solov in best_channel_gains:
          comp_latencies_b_co[0][solov] = comp_latencies_b_co[0][solov] + (beta1*(best_alphasss*S_u))
          if solov in duplicates:
            continue
          else:
            matches = [de for de,se in enumerate(best_channel_gains) if se==solov]
            #timeagain = np.argwhere(best_channel_gains == j)[0]
            #if more than 1 sum up the indices
            temp_sum_den_b = 0
            temp_sum_temp_b = 0
          for iterating in matches:
            temp_sum_den_b = temp_sum_den_b + sum_den_b[iterating]
            temp_sum_temp_b = temp_sum_temp_b + sum_temp_b[iterating]
          

          best_sums.append(temp_sum_temp_b)
          #delete from best_gains
          duplicates.append(solov)
          #duplicates.append(timeagain[0])
      
        for xv in range(len(best_sums)):
          copy_sums = np.asarray(best_sums.copy())
          copy_sums = np.delete(copy_sums,xv)
          #copy_sums.pop(xv)
          if len(copy_sums) == 0:
            copy_sums = 0.0
          rate_b = ((B*np.log2((1+best_sums[xv]/(1+copy_sums)))))
          #comp_latencies_b_co[0][duplicates[xv]] = comp_latencies_b_co[0][duplicates[xv]] + ((beta1*(best_alphasss*S_u*C)/freq))
          trans_latencies_b_co.append((beta2*(product_b/rate_b)))

        #actual_comp_lat_b =  np.sum(comp_latencies_b_co[0],axis=0)
        #actual_comp_lat_b = np.max((actual_comp_lat_b*C)/freq)
        actual_comp_lat_b = np.max((comp_latencies_b_co[0] * C) / freq)
        actual_trans_lat_b = np.mean(trans_latencies_b_co)
        final_rewards_b = actual_comp_lat_b + actual_trans_lat_b


        '''
        if best_channel_gains[0] == best_channel_gains[1]: # if same AP is chosen for both add them together. 
          sum_den_bb = np.sum(sum_den_b)
          sum_temp_bb = np.sum(sum_temp_b) #need to add for same alpha
          rate_b = ((B*np.log2((1+((sum_temp_bb)/(1+sum_den_bb))))))
          total_latency_b = (beta1*(best_alphasss*S_u*C)/freq) + (beta2*(product_b/rate_b))
          reward_b = total_latency_b #because now doing  for same alpha #2*total_latency_b #because same alpha
        else:  # if not they are sepearte entities
          for i in range(len(sum_den_b)):
            rate_b = ((B*np.log2((1+((sum_temp_b[i])/(1+sum_den_b[i]))))))
            total_latency_b = (beta1*(best_alphasss*S_u*C)/freq) + (beta2*(product_b/rate_b))
            latencies_b_co.append(total_latency_b)
          
          xx1_b = np.max(latencies_b_co[0])
          xx2_b = np.max(latencies_b_co[1])
          #reward_b =np.mean([xx1_b, xx2_b]) 
          reward_b = np.max([xx1_b, xx2_b]) 
          #reward_b =np.sum([xx1_b, xx2_b]) 
        '''
        reward_b = (final_rewards_b)

        '''
        if indexxx == ep*200: 
          old_reward_b = reward_b
        else:
          reward_b = reward_b - old_reward_b
          old_reward_b = reward_b
        '''
        
      

     
        const_reward_list.append(reward_b)
        '''
        indexxx = indexxx + num_user#2#1
        if indexxx < len(lines):
          complex_vec_total = converttt(lines,indexxx)
          state = []
          for iii in range(num_user):
            status =  np.empty((1, num_states), dtype=np.object)  #TODO: how to assign to None,30 or convert 1,1,30 to None,3
            for jwe in range(num_states):
              #status[0][jwe] = np.log2(np.absolute(complex_vec_total[iii][jwe]))
              #status[0][jwe] = un_dB_sinr[0][jwe]
              #status[0][jwe] = (un_dB_sinr[0][jwe])

              
              if jwe < num_APs:
                status[0][jwe] = un_dB_sinr[0][jwe]
              else:
                status[0][jwe] = (np.absolute(complex_vec_total[iii][jwe-num_APs]))
              
            
            status= status[0].astype('float64')
              #############state[0][iii] = (un_dB_sinr[0][iii])
            state.append(status)
            
           
          
          #state = state[0].astype('float64')
        else:
          print('Stop')
          break
        '''


        if indexxx == 12000:#3006:
            stop_now = 1
            break

        #print('State')
        #print(state)
        #print('Alphasss')
        #print(actions)

        
        
        



        '''
        print('Computational latency')
        print((beta1*(alphasss*S_u*C)/freq)) 
        print('Transmission Latency')
        print(beta2*(product/rate))
        '''
        
        '''
        for ew in range(num_user):
           buffer.record((prev_state[ew], actions[ew], reward, state[ew],copy_of_SINRS_co[ew],copy_of_products_co[ew])) 
        '''
           #buffer.record((prev_state[ew], actions[ew], copy_of_latencies_co[ew], state[ew]))

           ####buffer.record((prev_state[ew], actions[ew], reward, state[ew])) #dont know if this should be -reward or not
           #buffer.record((prev_state[ew], actions[ew], reward, state[ew],actions[ew]*S_u,rate)) #dont know if this should be -reward or not
           #############buffer.record((prev_state[ew], action[ew], final_rewards[ew], state[ew])) #dont know if this should be -reward or not


        ############buffer.record((prev_state, alphasss, reward, state)) #dont know if this should be -reward or not




        #indexxx = indexxx + 1
        #prev_state = state
        ep_reward_list.append(nn_latency.numpy())

        

    #ep_reward_list.append(episodic_reward)
    

    ## Mean of last 40 episodes
    ##avg_reward = np.mean(ep_reward_list[-40:])
    #print("Episode * {} * Avg Reward is ==> {}".format(ep, avg_reward))
    #vg_reward_list.append(avg_reward)

# Plotting graph
# Episodes versus Avg. Rewards
print(indexxx)
#count = b1/float(1000)
#print(count)

'''
stats = np.arange(0, 0.1, 0.0001)
#stats = np.arange(10, 5000, 10)
#stats = np.arange(2, 250, 2)
ep_cdf =np.zeros([1,len(stats)])[0]
unif_cdf =np.zeros([1,len(stats)])[0]
const_cdf =np.zeros([1,len(stats)])[0]
#solo1_cdf =np.zeros([1,len(stats)])[0]
#solo2_cdf =np.zeros([1,len(stats)])[0]
count = 0
for il in stats:
  #print('index ' + str(il))
  tata = len(np.argwhere(ep_reward_list<il))
  #print('count ' + str(tata))
  tata2 = len(np.argwhere(unif_reward_list<il))
  tata3 = len(np.argwhere(const_reward_list<il))
  tata4 = len(np.argwhere(solo1<il))
  tata5 = len(np.argwhere(solo2<il))
  ep_cdf[count] = tata/((200+ep*200)/num_user) #(1000+ep*1000)  (200+ep*200)
  unif_cdf[count] = tata2/((200+ep*200)/num_user)
  const_cdf[count] = tata3/((200+ep*200)/num_user)
  #solo1_cdf[count] = tata4/((200+ep*200)/2)
  #solo2_cdf[count] = tata4/((200+ep*200)/2)
  count = count + 1


plt.plot(stats,ep_cdf)
plt.plot(stats,unif_cdf)
plt.plot(stats,const_cdf)
#plt.plot(solo1_cdf)
#plt.plot(solo2_cdf)
plt.xlabel("Max Latency")
plt.ylabel("CDF")
plt.legend(['Distributed method w/DDPG', 'Uniform Method', 'Best Channel Method'])
plt.show()

print(ep_cdf)
print(unif_cdf)
'''
# Save the weights
critic_model.save_weights("sam260.h5")
#critic_model.save_weights("cell_critic.h5")

#target_actor.save_weights("cell_target_actor.h5")
#target_critic.save_weights("cell_target_critic.h5")

file2 = open('EFBACTUAL_RREDO_100meters_PRETTY_PLS_VER551_MULTIPLE_PATHS_LARGE_VER1_10AP_6_UE_50000SHAD_part2.txt', 'r')
testlines = file2.readlines()

pos = 0
raw_iq = []
complex_vec2 = []
complex_vec_total_p2 = []
count = 0
count2 = 0

for i in range(num_user):
  temp = testlines[pos+i]
  temp = temp.strip()
  temp = temp.split(' ')
  raw_iq.append(temp)
  print(raw_iq[i])

for i in range(num_user):
  for jslack in raw_iq[i]:
  #i = float(i)
    if count % 2 == 0:
      tens = float(raw_iq[i][count])
    if  count % 2 == 1:
      complex_vec2.append(complex(tens,float(raw_iq[i][count])))
      count2 = count2+ 1
    count = count + 1
  complex_vec_total_p2.append(complex_vec2)
  complex_vec2 = []
  count = 0
  count2 = 0

print(complex_vec_total_p2[0])
print(complex_vec_total_p2[1])

#load weights -- need to understand what's needed here during testing phase
critic_model.load_weights("sam260.h5")


# To store reward history of each episode
ep_reward_list = []
# To store average reward history of last few episodes
const_reward_list = []
unif_reward_list = []
new_reward = 0
best_alphas = np.zeros(shape=(1,num_APs))
#best_alphas = np.zeros(shape=(1,10))
b1  = 0
indexxx = 0
total_episodes = 1
# Takes about 4 min to train
for ep in range(total_episodes):

    #prev_state = env.reset() ep*1000
    prev_state = np.zeros([num_states,])
    episodic_reward = 0
    alphasss = []
    for i in range(num_user):
      rand_vecs = np.random.random(size=(1,num_APs))
      rand_vecs = rand_vecs/np.sum(rand_vecs)
      alphasss.append(rand_vecs[0])
    
    #indexxx = ep*1000
    #print('Step')
    #print(indexxx)
    #print(200+ep*200)
    '''
    comp, fla = converttt(lines,0)
    prev_state[0:10] = fla
    prev_state[10:21] = alphasss
    '''

    #while indexxx < len(testlines)-1:
    while indexxx < len(testlines)-(2*num_user-1):
        # Uncomment this to see the Actor in action
        # But not in a python notebook.
        # env.render()
        #print(prev_state)
        #prev_state = np.asarray(prev_state).astype(np.float32)  
        tf_prev_state = [[]]*num_user
        if indexxx > 0:
          for jwiw in range(num_user):
            tf_prev_state[jwiw] = (tf.expand_dims(tf.convert_to_tensor(prev_state[jwiw],dtype=np.float32), 0))
        else:
          for jwiw in range(num_user):
            tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state,dtype=np.float32), 0)

      
        actions = []
        
        if indexxx == 0:
          for ikea in range(num_user):
            actions.append(np.asarray(alphasss[ikea]))
        else:
          for ikea22 in range(num_user):
            actions.append(policy_testing(tf_prev_state[ikea22])[0])
          #action = softmax(tf_prev_state)
          ######action = action[0]
          
          #TO EXPERIMENT COMMENTING THIS OUT
          '''
          while 0 in action:
            action = policy(tf_prev_state, ou_noise)
            #action = softmax(tf_prev_state)
            action = action[0]
          '''
        comp_latencies_co = []
        trans_latencies_co = []
        comp_latencies_u_co = []
        trans_latencies_u_co = []
        comp_latencies_b_co = np.zeros(shape=(1,num_APs))
        trans_latencies_b_co = []
        latencies_co = []
        latencies_u_co = []
        latencies_b_co = []
        sum_temp = np.zeros(shape=(1,num_APs))
        sum_den = np.zeros(shape=(1,num_APs))
        sum_temp_u = np.zeros(shape=(1,num_APs))
        sum_den_u = np.zeros(shape=(1,num_APs))
        sum_temp_b = []
        sum_den_b = []
        for swag in range(num_user):
          action = actions[swag]
    
          alphasss = action
          ########################product = alphasss*S_u
          oneminussquared = (1-alphasss)**2
          squareddd = alphasss**2
          chan_squared = (np.absolute(complex_vec_total_p2[swag])**2)

          #num = ((B*np.log2(1+((p*ada_1)*(squareddd*chan_squared)))))
          ###########################den = 1+ ((p*ada_1)*(oneminussquared*chan_squared))
          den = ((p*ada_1)*(oneminussquared*chan_squared))





          temp = (((p*ada_1)*(squareddd*chan_squared)))
          ############################rate = ((B*np.log2((1+(((p*ada_1)*(squareddd*chan_squared))/den)))))


          sum_den[0] = sum_den[0] + den
          sum_temp[0] = sum_temp[0] + temp



          # should do this if somehow channel becomes zero (i.e. shadow)
        
        rate = ((B*np.log2((1+((sum_temp)/(1+sum_den))))))


        un_dB_sinr = ((sum_temp)/(1+sum_den))
        '''
        if indexxx > 0:
          print('Original')
          print(rate)
        '''
        #### CHecking ###
        
        for sew in range(num_user):
        
          alphasss_indices = np.where(actions[sew]==0)[0]
          print('Alphas Indices')
          print(alphasss_indices)


          new_rate = rate[0].copy()

          
          for i in alphasss_indices:  #setting rates where alpha = 0 to zero
            new_rate[i] = 0 

          print('Alphasss')
          print(actions[sew])
          new_alphasss = actions[sew][actions[sew] != 0]

          
          observing_rate_indices = np.where(new_rate==0)[0]
          observing_alphasss_indices = np.where(actions[sew]==0)[0]
          tezerk = len(observing_rate_indices)
          tezerk2 = len(observing_alphasss_indices)

          if tezerk != tezerk2:
            print('Size Damn it')
            print('chan squared')
            print(chan_squared)
            print('Alphas')
            print(alphasss)
            print('Temp')
            print(temp)
            print('Den')
            print(den)
            print('Rate')
            print(rate[0])
            print('New Rate')
            print(new_rate)
            quit()

          for excak in range(tezerk):
            if observing_rate_indices[excak] != observing_alphasss_indices[excak]:
              print('Damn it')
              print(chan_squared)
              print('Alphas')
              print(alphasss)
              print('Temp')
              print(temp)
              print('Den')
              print(den)
              print('Rate')
              print(rate[0])
              print('New Rate')
              print(new_rate)
              quit()
          



          ##TODO: FOR THE ALPHAS THAT ARE ZERO REMOVE THE CORRESPONDING INDICES FROM THE RATE EVEN IF NOT ZERO INSTEAD OF SEEING IF THEY MATCH
          new_rate = new_rate[new_rate != 0]
          product = actions[sew]*S_u

          product = product[product!=0]
          

        
      

  

          #un_dB_sinr = (2**(new_rate/B)) - 1


          #un_dB_sinr = ((((p*ada_1)*(squareddd*chan_squared))/den))




      # Recieve state and reward from environment.
      #state, reward, done, info = env.step(action)

          comp_latencies_co.append((beta1 *(actions[sew] * S_u ) ))
          trans_latencies_co.append(np.max(beta2*(product/new_rate)))
          
          #total_latency = (beta1*(new_alphasss*S_u*C)/freq) +  (beta2*(product/new_rate))
          #total_latency =  (beta2*(product/new_rate))

          #latencies_co.append(total_latency)
          
        

        actual_comp_lat =  np.sum(comp_latencies_co,axis=0)#np.max(comp_latencies_co)
        actual_comp_lat = np.max((actual_comp_lat*C)/freq)
        actual_trans_lat = np.mean(trans_latencies_co)
        final_rewards = actual_comp_lat + actual_trans_lat
        #final_rewards = []
        '''
        for fight in range(num_user):
          final_rewards.append(np.max(latencies_co[fight]))
        '''

        #xx1 = np.max(latencies_co[0])
        #xx2 = np.max(latencies_co[1])
        #reward =np.mean([xx1, xx2]) 
        #reward = np.max([xx1,xx2])
        reward = final_rewards #np.max(final_rewards)

        
        if indexxx >0 and indexxx < len(testlines):
          ep_reward_list.append(reward)

        #reward =np.sum([xx1, xx2]) 






      



        # End this episode when `done` is True
        #if done:
        #    break

        #prev_state = state
        #ep_reward_list.append(episodic_reward)

        ##### UNIFORM
        ##### UNIFORM
        unif_actions = []
        for delicious in range(num_user):
            # unif_alphasss = 1/num_APs*np.ones([1,num_APs])
            # unif_alphasss = 1/10*np.ones([1,10])
            unif_alphasss = 1 / 4 * np.ones([1, 10])[0]
            xcel = np.random.choice(10, 4, replace=False)
            for slap in range(len(unif_alphasss)):
                if slap not in xcel:
                    unif_alphasss[slap] = 0
            unif_actions.append(unif_alphasss)
            product_u = unif_alphasss * S_u
            oneminussquared_u = (1 - unif_alphasss) ** 2
            squareddd_u = unif_alphasss ** 2
            chan_squared_u = (np.absolute(complex_vec_total_p2[delicious]) ** 2)

            # num = ((B*np.log2(1+((p*ada_1)*(squareddd*chan_squared)))))
            ########################den_u = 1+ ((p*ada_1)*(oneminussquared_u*chan_squared_u))
            den_u = ((p * ada_1) * (oneminussquared_u * chan_squared_u))
            temp_u = (((p * ada_1) * (squareddd_u * chan_squared_u)))

            sum_den_u[0] = sum_den_u[0] + den_u
            sum_temp_u[0] = sum_temp_u[0] + temp_u
            comp_latencies_u_co.append(beta1 * (unif_alphasss * S_u))

            #########rate_u = ((B*np.log2((1+(((p*ada_1)*(squareddd_u*chan_squared_u))/den_u)))))

        rate_u = ((B * np.log2((1 + ((sum_temp_u) / (1 + sum_den_u))))))
        actual_comp_lat_u = np.sum(comp_latencies_u_co, axis=0)  # np.max(comp_latencies_co)
        actual_comp_lat_u = np.max((actual_comp_lat_u * C) / freq)

        for sewn in range(num_user):
            new_rate_u = rate_u[0].copy()
            zero_u_indic = np.where(unif_actions[sewn] == 0)[0]

            for i in zero_u_indic:  # setting rates where alpha = 0 to zero
                new_rate_u[i] = 0

            new_alphasss_u = unif_actions[sewn][unif_actions[sewn] != 0]

            observing_rate_indices = np.where(new_rate_u == 0)[0]
            observing_alphasss_indices = np.where(unif_actions[sewn] == 0)[0]
            observing_alphasss_indices_extra = np.where(unif_actions[sewn] != 0)[0]
            tezerk = len(observing_rate_indices)
            tezerk2 = len(observing_alphasss_indices)

            if tezerk != tezerk2:
                print('Size Damn it')
                print('Rate')
                print(new_rate_u)
                print('alphas')
                print(new_alphasss_u)
                quit()

            for excak in range(tezerk):
                if observing_rate_indices[excak] != observing_alphasss_indices[excak]:
                    print('Damn it')
                    print('Rate')
                    print(new_rate_u)
                    print('alphas')
                    print(new_alphasss_u)
                    quit()

            new_rate_u = new_rate_u[new_rate_u != 0]
            product_u = new_alphasss_u * S_u
            product_u = product_u[product_u != 0]
            trans_latencies_u_co.append(np.max(beta2 * (product_u / new_rate_u)))

        actual_trans_lat_u = np.mean(trans_latencies_u_co)
        # total_latency_u = (beta1*(unif_alphasss*S_u*C)/freq) + (beta2*(product_u/rate_u))
        # total_latency_u =  (beta2*(product_u/rate_u))
        # because alphas are always uniform for both users, can just multiply reward by 2.

        reward_u = actual_trans_lat_u + actual_comp_lat_u
        #total_latency_u = (beta1*(unif_alphasss*S_u*C)/freq) + (beta2*(product_u/rate_u))
        #total_latency_u = (beta2*(product_u/rate_u))
        #because alphas are always uniform for both users, can just multiply reward by 2. 
        #reward_u = 2*np.max(total_latency_u[0])  
        '''
        latencies_u_co.append(total_latency_u[0])
        xx1_u = np.max(latencies_u_co[0])
        xx2_u = np.max(latencies_u_co[1])
        reward_u =np.sum([xx1_u, xx2_u]) 
       '''
        
        ##NEW - 7/16
        if indexxx >0 and indexxx < len(testlines):
          unif_reward_list.append(reward_u)


        #### BEST Method
        best_channel_gains = []
        final_best_reward = []
        #### BEST Method
        for great in range(num_user):
          best_id = np.argmax(np.abs(complex_vec_total_p2)[great])
          best_channel_gains.append(best_id)
          best_alphasss = 1

          product_b = best_alphasss*S_u
          oneminussquared_b = (1-best_alphasss)**2
          squareddd_b = best_alphasss**2

          chan_squared_b = (np.absolute(complex_vec_total_p2[great][best_id])**2)

          #num = ((B*np.log2(1+((p*ada_1)*(squareddd*chan_squared)))))
          #####################den_b = 1+ ((p*ada_1)*(oneminussquared_b*chan_squared_b))
          den_b = ((p*ada_1)*(oneminussquared_b*chan_squared_b))
          temp_b = (((p*ada_1)*(squareddd_b*chan_squared_b)))
          sum_den_b.append(den_b)
          sum_temp_b.append(temp_b)
          #####################rate_b = ((B*np.log2((1+(((p*ada_1)*(squareddd_b*chan_squared_b))/den_b)))))
         
        duplicates = []
        best_sums = []
        for solovvv in best_channel_gains:
          comp_latencies_b_co[0][solovvv] = comp_latencies_b_co[0][solovvv] + (beta1*(best_alphasss*S_u))
          if solovvv in duplicates:
            continue
          else:
            matches = [deee for deee,see in enumerate(best_channel_gains) if see==solovvv]
            #timeagain = np.argwhere(best_channel_gains == j)[0]
            #if more than 1 sum up the indices
            #temp_sum_den_b = 0
            temp_sum_temp_b = 0
          for iterating in matches:
            #temp_sum_den_b = temp_sum_den_b + sum_den_b[iterating]
            temp_sum_temp_b = temp_sum_temp_b + sum_temp_b[iterating]
          
          best_sums.append(temp_sum_temp_b)
          #delete from best_gains
          duplicates.append(solovvv)
          #duplicates.append(timeagain[0])
        
        for xv in range(len(best_sums)):
          copy_sums = np.asarray(best_sums.copy())
          copy_sums = np.delete(copy_sums,xv)
          #copy_sums.pop(xv)
          if len(copy_sums) == 0:
            copy_sums = 0.0
          rate_b = ((B*np.log2((1+best_sums[xv]/(1+copy_sums)))))
          #comp_latencies_b_co[0][duplicates[xv]] = comp_latencies_b_co[0][duplicates[xv]] + ((beta1*(best_alphasss*S_u*C)/freq))
          trans_latencies_b_co.append((beta2*(product_b/rate_b)))

        #actual_comp_lat_b =  np.sum(comp_latencies_b_co[0],axis=0)
        #actual_comp_lat_b = np.max((actual_comp_lat_b*C)/freq)
        actual_comp_lat_b = np.max((comp_latencies_b_co[0] * C) / freq)
        actual_trans_lat_b = np.mean(trans_latencies_b_co)
        final_rewards_b = actual_comp_lat_b + actual_trans_lat_b
          #####total_latency_b = (beta1*(best_alphasss*S_u*C)/freq) + (beta2*(product_b/rate_b))
          #total_latency_b = (beta2*(product_b/rate_b))
          ######latencies_b_co.append(total_latency_b)


        '''


        if best_channel_gains[0] == best_channel_gains[1]: # if same AP is chosen for both add them together. 
          sum_den_bb = np.sum(sum_den_b)
          sum_temp_bb = np.sum(sum_temp_b) #need to add for same alpha
          rate_b = ((B*np.log2((1+((sum_temp_bb)/(1+sum_den_bb))))))
          total_latency_b = (beta1*(best_alphasss*S_u*C)/freq) + (beta2*(product_b/rate_b))
          reward_b = total_latency_b #because same alpha
        else:  # if not they are sepearte entities
          for i in range(len(sum_den_b)):
            rate_b = ((B*np.log2((1+((sum_temp_b[i])/(1+sum_den_b[i]))))))
            total_latency_b = (beta1*(best_alphasss*S_u*C)/freq) + (beta2*(product_b/rate_b))
            latencies_b_co.append(total_latency_b)
          
          xx1_b = np.max(latencies_b_co[0])
          xx2_b = np.max(latencies_b_co[1])
          #reward_b =np.mean([xx1_b, xx2_b]) 
          reward_b =np.max([xx1_b, xx2_b]) 
          #reward_b =np.sum([xx1_b, xx2_b]) 
        '''

        reward_b = (final_rewards_b)

      
       
         #NEW - 7/16
        if indexxx > 0 and indexxx < len(testlines):
          const_reward_list.append(reward_b)

        print('Step')
        print(indexxx)
        indexxx = indexxx + num_user #2#1
        if indexxx < len(testlines):
          complex_vec_total_p2 = converttt(testlines,indexxx)
          state = []
          for iii in range(num_user):
            status =  np.empty((1, num_states), dtype=np.object)  #TODO: how to assign to None,30 or convert 1,1,30 to None,3
            for jwe in range(num_states):
              #status[0][jwe] = np.log2(np.absolute(complex_vec_total_p2[iii][jwe])) #un_dB_sinr[0][jwe]
              #status[0][jwe] = (un_dB_sinr[0][jwe])
              
              if jwe < num_APs:
                status[0][jwe] = un_dB_sinr[0][jwe]
              else:
                status[0][jwe] = (np.absolute(complex_vec_total_p2[iii][jwe-num_APs]))
              #latencies_co[iii][jwe] #Go back to sinr instead??
              
            
            status= status[0].astype('float64')
              #############state[0][iii] = (un_dB_sinr[0][iii])
            state.append(status)
            
           
          
          #state = state[0].astype('float64')
        else:
          print('Stop')
          break
        
        
        '''
        print('State')
        print(state)
        '''
        '''
        print('Alphasss')
        print(action)
        '''
        print('Reward')
        print(reward)
        #print('Uniform reward')
        #print(reward_u)
        
        



        
        print('Computational latency')
        print((beta1*(new_alphasss*S_u*C)/freq)) 
        print('Transmission Latency')
        print(beta2*(product/new_rate))

        

        ############buffer.record((prev_state, alphasss, reward, state)) #dont know if this should be -reward or not
          
        #episodic_reward = (reward)
        
        #indexxx = indexxx + 1
        prev_state = state

        #ep_reward_list.append(episodic_reward)

        

    #ep_reward_list.append(episodic_reward)
    

    ## Mean of last 40 episodes
    ##avg_reward = np.mean(ep_reward_list[-40:])
    #print("Episode * {} * Avg Reward is ==> {}".format(ep, avg_reward))
    #vg_reward_list.append(avg_reward)

# Plotting graph
# Episodes versus Avg. Rewards
print(indexxx)
#count = b1/float(1000)
#print(count)

print(len(testlines))
print(len(ep_reward_list))
print(len(unif_reward_list))
print(len(const_reward_list))

print(num_APs)


min_cdf_mean = [0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000]
#min_cdf_mean  = [0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000]

min_sqp = [0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000, 1.00000000]

#min_interior_cdf  = [0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.00300300, 0.01801802, 0.05305305, 0.08808809, 0.11711712, 0.15315315, 0.18318318, 0.20520521, 0.22822823, 0.24924925, 0.26726727, 0.28328328, 0.30530531, 0.32832833, 0.35035035, 0.36636637, 0.38138138, 0.39239239, 0.40240240, 0.41441441, 0.42442442, 0.43443443, 0.44644645, 0.45345345, 0.46046046, 0.47047047, 0.47947948, 0.48448448, 0.49149149, 0.49349349, 0.49549550, 0.50850851, 0.51251251, 0.51551552, 0.52252252, 0.52952953, 0.53553554, 0.54154154, 0.54954955, 0.55355355, 0.56056056, 0.56256256, 0.56856857, 0.57057057, 0.57657658, 0.57957958, 0.58358358, 0.59259259, 0.59459459, 0.59959960, 0.60560561, 0.61161161, 0.61461461, 0.62262262, 0.62462462, 0.62862863, 0.63663664, 0.64064064, 0.64264264, 0.64664665, 0.65465465, 0.65965966, 0.66266266, 0.66866867, 0.67167167, 0.67667668, 0.68268268, 0.68668669, 0.69069069, 0.69269269, 0.69569570, 0.69869870, 0.70170170, 0.70370370, 0.70670671, 0.71071071, 0.71271271, 0.71671672, 0.71871872, 0.72172172, 0.72272272, 0.72772773, 0.73273273, 0.73473473, 0.73773774, 0.73873874, 0.74174174, 0.74274274, 0.74474474, 0.74574575, 0.74874875, 0.75375375, 0.75475475, 0.75575576, 0.75975976, 0.76276276, 0.76476476, 0.76676677, 0.76776777, 0.76876877, 0.76876877, 0.76876877, 0.76876877, 0.77077077, 0.77377377, 0.77677678, 0.77777778, 0.77977978, 0.77977978, 0.78178178, 0.78578579, 0.78778779, 0.78878879, 0.79379379, 0.79679680, 0.79879880, 0.79979980, 0.80180180, 0.80180180, 0.80180180, 0.80280280, 0.80480480, 0.80580581, 0.80780781, 0.80980981, 0.80980981, 0.80980981, 0.80980981, 0.80980981, 0.80980981, 0.80980981, 0.81081081, 0.81081081, 0.81481481, 0.81581582, 0.81681682, 0.81781782, 0.81781782, 0.81781782, 0.82182182, 0.82182182, 0.82282282, 0.82582583, 0.82582583, 0.82582583, 0.82682683, 0.82782783, 0.82982983, 0.83083083, 0.83283283, 0.83483483, 0.83483483, 0.83583584, 0.83683684, 0.83783784, 0.83883884, 0.83983984, 0.83983984, 0.84184184, 0.84184184, 0.84184184, 0.84184184, 0.84184184, 0.84184184, 0.84184184, 0.84184184, 0.84384384, 0.84384384, 0.84384384, 0.84484484, 0.84484484, 0.84784785, 0.84784785, 0.84884885, 0.84884885, 0.84984985, 0.84984985, 0.85185185, 0.85185185, 0.85285285, 0.85385385, 0.85585586, 0.85585586, 0.85585586, 0.85785786, 0.85885886, 0.85885886, 0.85985986, 0.86186186, 0.86186186, 0.86186186, 0.86186186, 0.86186186]
#4_4 CPU - 128 64  14526 (14520 completed) 25 APs - 6mUEs tf_reduce mean tanh tanh linear   increase buffer to 1500  and now back to 120 redo interior cdf though
stats22 = np.arange(0, 0.2, 0.001)
#stats22 = np.arange(5, 300, 5) #400
ep_cdf22 =np.zeros([1,len(stats22)])[0]
unif_cdf22 =np.zeros([1,len(stats22)])[0]
const_cdf22 =np.zeros([1,len(stats22)])[0]
count22 = 0
for il in stats22:
  tata22 = len(np.argwhere(ep_reward_list<=il))
  tata222 = len(np.argwhere(unif_reward_list<=il))
  tata223 = len(np.argwhere(const_reward_list<=il))
  ep_cdf22[count22] = tata22/len(ep_reward_list)#999#1000
  unif_cdf22[count22] = tata222/len(unif_reward_list)#999#1000
  const_cdf22[count22] = tata223/len(const_reward_list)#999#1000
  count22 = count22 + 1

#plt.xlim(0, 70)
plt.plot(stats22*1000,ep_cdf22)
plt.plot(stats22*1000,unif_cdf22)
plt.plot(stats22*1000,const_cdf22)
plt.plot(stats22*1000,min_cdf_mean,marker='s')
plt.plot(stats22*1000,min_sqp,marker='*')
plt.title('Comparison of Message Allocation Methods under $L_{1}^{Max}$ - 10 APs & 6 UEs')
plt.xlabel("Max Latency (ms)")
plt.ylabel("CDF")
plt.legend(['Semi-Decentralized Method [This Paper]', 'Uniform Allocation', 'Greedy Allocation','Centralized Method [Interior Point]','Centralized Method [SQP]'])
plt.show()

print('ep reward list')
print(ep_reward_list)
print('unif reward list')
print(unif_reward_list)
print('const reward list')
print(const_reward_list)
print('ep cdf22')
print(ep_cdf22)
print('unif cdf22')
print(unif_cdf22)
print('const cdf22')
print(const_cdf22)